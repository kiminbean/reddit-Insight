---
phase: 05-trend-analysis
plan: 02
type: execute
depends_on: ["05-01"]
files_modified: [src/reddit_insight/analysis/keywords.py, src/reddit_insight/analysis/tfidf.py]
---

<objective>
키워드 추출 엔진을 구현한다.

Purpose: 텍스트에서 중요한 키워드/키프레이즈 자동 추출
Output: YAKE 기반 단일 문서 추출, TF-IDF 기반 코퍼스 추출
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-plan.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/05-trend-analysis/05-01-PLAN.md

**Research findings:**
- YAKE: 통계 기반, 단일 문서에서 키워드 추출, 학습 불필요
- TF-IDF: 코퍼스 전체에서 중요 단어 식별, scikit-learn 사용

**Prior plan context:**
- RedditTokenizer, StopwordManager 구현됨
- 불용어 처리 가능

**Keyword scoring:**
- YAKE: 낮은 점수 = 더 중요
- TF-IDF: 높은 점수 = 더 중요
</context>

<tasks>

<task type="auto">
  <name>Task 1: YAKE 키워드 추출기</name>
  <files>src/reddit_insight/analysis/keywords.py</files>
  <action>
  src/reddit_insight/analysis/keywords.py 생성:

  1. Keyword 데이터 클래스:
     - keyword: str
     - score: float
     - frequency: int | None = None

  2. KeywordExtractorConfig 데이터 클래스:
     - max_ngram_size: int = 3
     - deduplication_threshold: float = 0.9
     - num_keywords: int = 20
     - language: str = "en"

  3. YAKEExtractor 클래스:
     - __init__(config: KeywordExtractorConfig | None = None)
     - _yake_extractor: yake.KeywordExtractor

  4. 메서드:
     - extract(text: str) -> list[Keyword]:
       - 단일 텍스트에서 키워드 추출
       - 점수 정규화 (0-1, 높을수록 중요)
     - extract_from_texts(texts: list[str]) -> list[Keyword]:
       - 여러 텍스트 합쳐서 추출
     - extract_from_posts(posts: list[Post]) -> list[Keyword]:
       - Post 객체에서 title + selftext 결합

  주의:
  - YAKE 점수는 낮을수록 중요 → 반전하여 정규화
  - 중복 제거 threshold 조정 가능
  </action>
  <verify>
  - python -c "import sys; sys.path.insert(0, 'src'); from reddit_insight.analysis.keywords import YAKEExtractor; y = YAKEExtractor(); kws = y.extract('Python is a great programming language for data science and machine learning'); print([(k.keyword, round(k.score, 2)) for k in kws[:5]])"
  </verify>
  <done>
  - YAKEExtractor가 단일/다중 텍스트 키워드 추출
  - 정규화된 점수 반환
  </done>
</task>

<task type="auto">
  <name>Task 2: TF-IDF 분석기</name>
  <files>src/reddit_insight/analysis/tfidf.py</files>
  <action>
  src/reddit_insight/analysis/tfidf.py 생성:

  1. TFIDFConfig 데이터 클래스:
     - max_features: int = 1000
     - min_df: int = 2 (최소 문서 빈도)
     - max_df: float = 0.95 (최대 문서 빈도)
     - ngram_range: tuple[int, int] = (1, 2)
     - use_idf: bool = True

  2. TFIDFAnalyzer 클래스:
     - __init__(config: TFIDFConfig | None = None)
     - _vectorizer: TfidfVectorizer
     - _tokenizer: RedditTokenizer
     - _fitted: bool = False
     - _feature_names: list[str] | None

  3. 메서드:
     - fit(texts: list[str]):
       - 코퍼스에 맞게 벡터라이저 학습
     - transform(texts: list[str]) -> sparse_matrix:
       - TF-IDF 벡터 변환
     - fit_transform(texts: list[str]) -> sparse_matrix

  4. 키워드 추출:
     - get_top_keywords(n: int = 20) -> list[Keyword]:
       - 전체 코퍼스에서 상위 키워드
     - get_document_keywords(text: str, n: int = 10) -> list[Keyword]:
       - 단일 문서의 상위 키워드
     - get_keywords_by_document(texts: list[str], n: int = 5) -> list[list[Keyword]]:
       - 각 문서별 키워드

  5. 유틸리티:
     - get_vocabulary() -> dict[str, int]: 어휘 사전
     - save(path: str): 학습된 벡터라이저 저장
     - load(path: str): 벡터라이저 로드
  </action>
  <verify>
  - python -c "import sys; sys.path.insert(0, 'src'); from reddit_insight.analysis.tfidf import TFIDFAnalyzer; t = TFIDFAnalyzer(); t.fit(['Python programming', 'Data science with Python', 'Machine learning algorithms']); print(t.get_top_keywords(5))"
  </verify>
  <done>
  - TFIDFAnalyzer가 코퍼스 기반 키워드 분석
  - 문서별/전체 키워드 추출 가능
  </done>
</task>

<task type="auto">
  <name>Task 3: 통합 키워드 추출기</name>
  <files>src/reddit_insight/analysis/keywords.py</files>
  <action>
  keywords.py에 통합 클래스 추가:

  1. KeywordMethod 열거형:
     - YAKE: 단일 문서 통계 기반
     - TFIDF: 코퍼스 기반
     - COMBINED: 두 방법 결합

  2. UnifiedKeywordExtractor 클래스:
     - __init__(method: KeywordMethod = KeywordMethod.YAKE)
     - _yake: YAKEExtractor
     - _tfidf: TFIDFAnalyzer | None

  3. 메서드:
     - extract_keywords(
         texts: list[str],
         num_keywords: int = 20,
         method: KeywordMethod | None = None
       ) -> list[Keyword]:
       - 지정된 방법으로 키워드 추출
     - extract_from_posts(
         posts: list[Post],
         num_keywords: int = 20
       ) -> list[Keyword]:
       - Post 객체에서 직접 추출

  4. 결합 방법 (COMBINED):
     - 두 방법의 결과를 병합
     - 점수 평균화 또는 가중 평균
     - 중복 제거

  5. 결과 포맷:
     - KeywordResult 데이터 클래스:
       - keywords: list[Keyword]
       - method: KeywordMethod
       - document_count: int
       - extracted_at: datetime
  </action>
  <verify>
  - python -c "import sys; sys.path.insert(0, 'src'); from reddit_insight.analysis.keywords import UnifiedKeywordExtractor, KeywordMethod; e = UnifiedKeywordExtractor(); print('UnifiedKeywordExtractor OK')"
  </verify>
  <done>
  - 통합 키워드 추출기로 여러 방법 선택 가능
  - Post 객체 직접 처리 지원
  </done>
</task>

<task type="auto">
  <name>Task 4: export 업데이트</name>
  <files>src/reddit_insight/analysis/__init__.py</files>
  <action>
  __init__.py 업데이트:
  - Keyword, KeywordResult export
  - YAKEExtractor, TFIDFAnalyzer export
  - UnifiedKeywordExtractor, KeywordMethod export
  - __all__ 업데이트
  </action>
  <verify>
  - python -c "import sys; sys.path.insert(0, 'src'); from reddit_insight.analysis import UnifiedKeywordExtractor, YAKEExtractor, TFIDFAnalyzer, Keyword; print('All keyword exports OK')"
  </verify>
  <done>
  - 키워드 추출 모듈 export 완료
  </done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] YAKEExtractor가 단일 문서 키워드 추출
- [ ] TFIDFAnalyzer가 코퍼스 기반 분석
- [ ] UnifiedKeywordExtractor로 통합 사용 가능
- [ ] 모듈 export 정상
</verification>

<success_criteria>

- 모든 태스크 완료
- 키워드 추출 엔진 동작
- YAKE와 TF-IDF 모두 지원

</success_criteria>

<output>
After completion, create `.planning/phases/05-trend-analysis/05-02-SUMMARY.md`
</output>
