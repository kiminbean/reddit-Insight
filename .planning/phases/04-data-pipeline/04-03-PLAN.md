---
phase: 04-data-pipeline
plan: 03
type: execute
depends_on: ["04-02"]
files_modified: [src/reddit_insight/pipeline/scheduler.py, src/reddit_insight/pipeline/collector.py, src/reddit_insight/cli.py]
---

<objective>
데이터 수집 스케줄러를 구현한다.

Purpose: 정기적인 데이터 수집 및 CLI 인터페이스 제공
Output: Collector 클래스, 간단한 스케줄러, CLI 명령어
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-plan.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-data-pipeline/04-02-PLAN.md

**Prior plan context:**
- DataPipeline, Repository 패턴 구현됨
- UnifiedDataSource로 데이터 수집 가능
- Database 연결 관리됨

**Requirements:**
- 서브레딧별 정기 수집
- 수집 이력 관리
- CLI로 수동 수집 트리거
- 로컬 개발 환경 (외부 스케줄러 서비스 없이)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Collector 클래스 구현</name>
  <files>src/reddit_insight/pipeline/collector.py</files>
  <action>
  src/reddit_insight/pipeline/collector.py 생성:

  1. CollectorConfig 데이터 클래스:
     - subreddit: str
     - sort: str = "hot"
     - limit: int = 100
     - include_comments: bool = False
     - comment_limit: int = 50

  2. Collector 클래스:
     - __init__(database: Database | None = None, data_source: UnifiedDataSource | None = None)
     - _db: Database
     - _data_source: UnifiedDataSource
     - _pipeline: DataPipeline

  3. 수집 메서드:
     - async collect_subreddit(config: CollectorConfig) -> CollectionResult
       - 단일 서브레딧 수집
     - async collect_multiple(configs: list[CollectorConfig]) -> list[CollectionResult]
       - 여러 서브레딧 순차 수집
     - async collect_from_list(subreddits: list[str], **kwargs) -> list[CollectionResult]
       - 간편 수집 메서드

  4. CollectionResult 데이터 클래스:
     - subreddit: str
     - posts_result: ProcessingResult
     - comments_result: ProcessingResult | None
     - duration_seconds: float
     - collected_at: datetime
     - error: str | None
  </action>
  <verify>
  - python -c "import sys; sys.path.insert(0, 'src'); from reddit_insight.pipeline.collector import Collector, CollectorConfig; print('Collector OK')"
  </verify>
  <done>
  - Collector 클래스가 데이터 수집 통합
  - 결과 추적 및 에러 처리
  </done>
</task>

<task type="auto">
  <name>Task 2: 간단한 스케줄러 구현</name>
  <files>src/reddit_insight/pipeline/scheduler.py</files>
  <action>
  src/reddit_insight/pipeline/scheduler.py 생성:

  1. ScheduleConfig 데이터 클래스:
     - subreddits: list[str]
     - interval_minutes: int = 60
     - sort: str = "hot"
     - limit: int = 100
     - include_comments: bool = False

  2. SimpleScheduler 클래스:
     - __init__(collector: Collector, config: ScheduleConfig)
     - _collector: Collector
     - _config: ScheduleConfig
     - _running: bool
     - _last_run: datetime | None
     - _run_history: list[ScheduleRun]

  3. 스케줄러 메서드:
     - async run_once() -> list[CollectionResult]:
       - 한 번 실행
     - async start(max_runs: int | None = None):
       - 반복 실행 시작
       - max_runs로 실행 횟수 제한 가능
     - stop():
       - 실행 중지
     - get_status() -> SchedulerStatus

  4. ScheduleRun 데이터 클래스:
     - run_id: int
     - started_at: datetime
     - completed_at: datetime
     - results: list[CollectionResult]
     - success: bool

  주의:
  - asyncio.sleep()으로 간격 대기
  - 외부 의존성 없이 순수 Python 구현
  - 프로덕션용 스케줄러는 별도 (cron, APScheduler 등)
  </action>
  <verify>
  - python -c "import sys; sys.path.insert(0, 'src'); from reddit_insight.pipeline.scheduler import SimpleScheduler, ScheduleConfig; print('Scheduler OK')"
  </verify>
  <done>
  - 간단한 인터벌 스케줄러 구현
  - 실행 이력 추적
  </done>
</task>

<task type="auto">
  <name>Task 3: CLI 인터페이스 구현</name>
  <files>src/reddit_insight/cli.py, pyproject.toml</files>
  <action>
  1. src/reddit_insight/cli.py 생성:

  CLI 명령어 (rich 사용):
  - collect 명령:
    - reddit-insight collect <subreddit> [--sort hot|new|top] [--limit 100] [--comments]
    - 단일 서브레딧 수집

  - collect-list 명령:
    - reddit-insight collect-list <file> 또는 stdin
    - 서브레딧 목록 파일에서 수집

  - status 명령:
    - reddit-insight status
    - 데이터베이스 통계 표시

  2. 구현:
     - click 또는 typer 사용하지 않고 argparse + rich
     - async 함수를 asyncio.run()으로 실행
     - 진행 상황 표시 (rich.progress)
     - 결과 테이블 출력 (rich.table)

  3. pyproject.toml에 진입점 추가:
     - [project.scripts]
     - reddit-insight = "reddit_insight.cli:main"
  </action>
  <verify>
  - python -c "import sys; sys.path.insert(0, 'src'); from reddit_insight.cli import main; print('CLI OK')"
  - cat pyproject.toml | grep "reddit-insight"
  </verify>
  <done>
  - CLI로 수동 데이터 수집 가능
  - 진행 상황 및 결과 표시
  </done>
</task>

<task type="auto">
  <name>Task 4: export 및 테스트</name>
  <files>src/reddit_insight/pipeline/__init__.py, tests/test_pipeline.py</files>
  <action>
  1. pipeline/__init__.py 업데이트:
     - Collector, CollectorConfig, CollectionResult export
     - SimpleScheduler, ScheduleConfig export
     - __all__ 업데이트

  2. tests/test_pipeline.py 생성:
     - TestTextPreprocessor: 텍스트 정제 테스트
     - TestCollector: 수집 로직 테스트 (모킹)
     - 기본 단위 테스트

  3. 통합 확인:
     - 전체 파이프라인 import 테스트
  </action>
  <verify>
  - python -c "import sys; sys.path.insert(0, 'src'); from reddit_insight.pipeline import Collector, SimpleScheduler, DataPipeline, TextPreprocessor; print('All pipeline exports OK')"
  - python -m pytest tests/test_pipeline.py -v --collect-only 2>/dev/null || echo "Tests defined"
  </verify>
  <done>
  - Phase 4 모든 기능 export됨
  - CLI 진입점 설정됨
  - 기본 테스트 작성됨
  </done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] Collector가 데이터 수집 및 저장 통합
- [ ] SimpleScheduler가 정기 수집 지원
- [ ] CLI로 수동 수집 가능
- [ ] 테스트 파일 존재
</verification>

<success_criteria>

- 모든 태스크 완료
- 데이터 수집 파이프라인 end-to-end 동작
- CLI로 기본 작업 수행 가능
- Phase 4 완료

</success_criteria>

<output>
After completion, create `.planning/phases/04-data-pipeline/04-03-SUMMARY.md`
</output>
